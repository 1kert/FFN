# feedforward neural network
hidden layer activations - ReLu  
output layer activations - Sigmoid
